{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d378dbf",
   "metadata": {},
   "source": [
    "# LSTM Stock Prediction Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e04c0b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Introduction](#1-introduction)\n",
    "2. [Libraries](#2-libraries)  \n",
    "3. [Data Collection](#3-data-collection)  \n",
    "4. [Data Exploration](#4-data-exploration)  \n",
    "5. [Feature Engineering](#5-feature-engineering)  \n",
    "6. [Model Architecture](#6-model-architecture)  \n",
    "7. [Training & Evaluation](#7-training--evaluation)  \n",
    "8. [Results & Diagnostics](#8-results--diagnostics)  \n",
    "9. [Conclusion](#9-conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0b00b9",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1004edbd",
   "metadata": {},
   "source": [
    "## 2. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03ba031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "# Machine Learning Libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mplfinance as mpf\n",
    "\n",
    "# Alpaca Libraries\n",
    "from alpaca.data.historical import StockHistoricalDataClient\n",
    "from alpaca.data.requests import StockBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "\n",
    "# Statistical Libraries\n",
    "from scipy.stats import entropy\n",
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d7bb5d",
   "metadata": {},
   "source": [
    "## 3. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbb5187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Gather data from Alpaca\n",
    "client = StockHistoricalDataClient(os.getenv('ALPACA_API_KEY'), os.getenv('ALPACA_SECRET_KEY'))\n",
    "request_params = StockBarsRequest(\n",
    "    symbol_or_symbols=[\"AAPL\"],\n",
    "    timeframe=TimeFrame.Day,\n",
    "    start=datetime(2016, 7, 1),\n",
    "    end=datetime(2025, 7, 1)\n",
    ")\n",
    "bars = client.get_stock_bars(request_params)\n",
    "\n",
    "# Convert to DataFrane\n",
    "df = bars.df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b889b303",
   "metadata": {},
   "source": [
    "## 4. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ff77a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head of DataFrame:\n",
      "  symbol                 timestamp   open    high    low  close      volume  \\\n",
      "0   AAPL 2016-07-01 04:00:00+00:00  95.49  96.465  95.33  95.89  27180926.0   \n",
      "1   AAPL 2016-07-05 04:00:00+00:00  95.39  95.400  94.46  95.04  30590138.0   \n",
      "2   AAPL 2016-07-06 04:00:00+00:00  94.60  95.660  94.37  95.53  32320508.0   \n",
      "3   AAPL 2016-07-07 04:00:00+00:00  95.70  96.500  95.62  95.94  26759405.0   \n",
      "4   AAPL 2016-07-08 04:00:00+00:00  96.49  96.890  96.05  96.68  30976552.0   \n",
      "\n",
      "   trade_count       vwap  \n",
      "0     154544.0  95.995066  \n",
      "1     153278.0  94.848509  \n",
      "2     187589.0  95.158127  \n",
      "3     143923.0  96.051727  \n",
      "4     168615.0  96.635640  \n"
     ]
    }
   ],
   "source": [
    "print(\"Head of DataFrame:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87b6f56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2261 entries, 0 to 2260\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype              \n",
      "---  ------       --------------  -----              \n",
      " 0   symbol       2261 non-null   object             \n",
      " 1   timestamp    2261 non-null   datetime64[ns, UTC]\n",
      " 2   open         2261 non-null   float64            \n",
      " 3   high         2261 non-null   float64            \n",
      " 4   low          2261 non-null   float64            \n",
      " 5   close        2261 non-null   float64            \n",
      " 6   volume       2261 non-null   float64            \n",
      " 7   trade_count  2261 non-null   float64            \n",
      " 8   vwap         2261 non-null   float64            \n",
      "dtypes: datetime64[ns, UTC](1), float64(7), object(1)\n",
      "memory usage: 159.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n DataFrame Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1f00195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " DataFrame Descriptive Statistics:\n",
      "              open         high          low        close        volume  \\\n",
      "count  2261.000000  2261.000000  2261.000000  2261.000000  2.261000e+03   \n",
      "mean    182.703186   184.678842   180.916845   182.912084  5.948293e+07   \n",
      "std      58.044565    58.851109    57.386703    58.246307  3.868233e+07   \n",
      "min      94.600000    95.400000    94.370000    95.040000  2.080515e+06   \n",
      "25%     145.660000   147.230000   144.370000   145.910000  3.100255e+07   \n",
      "50%     172.400000   174.010000   170.970000   172.570000  4.871406e+07   \n",
      "75%     204.430000   207.160000   202.586900   204.610000  7.803178e+07   \n",
      "max     514.790000   515.140000   500.330000   506.090000  3.570209e+08   \n",
      "\n",
      "        trade_count         vwap  \n",
      "count  2.261000e+03  2261.000000  \n",
      "mean   4.735065e+05   182.881165  \n",
      "std    3.062269e+05    58.176753  \n",
      "min    3.000000e+00    94.848509  \n",
      "25%    2.021250e+05   145.814255  \n",
      "50%    4.770020e+05   172.638542  \n",
      "75%    6.347160e+05   204.960355  \n",
      "max    2.962331e+06   505.287645  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n DataFrame Descriptive Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253df358",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "In this section, we enrich the raw OHLCV data with meaningful derived features. These help the LSTM model learn more nuanced temporal patterns. beyond just raw price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae47f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Datetime index\n",
    "df['date'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba3162",
   "metadata": {},
   "source": [
    "### 5.1 Price-Based Features\n",
    "\n",
    "We begin by generating basic transformations of open, high, low, and close to give the model awareness of price structure and returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6511899b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"close_lag_1\"] = df[\"close\"].shift(1)\n",
    "df[\"close_lag_2\"] = df[\"close\"].shift(2)\n",
    "df[\"close_minus_open\"] = df[\"close\"] - df[\"open\"]\n",
    "df[\"high_minus_low\"] = df[\"high\"] - df[\"low\"]\n",
    "df[\"close_over_open\"] = df[\"close\"] / df[\"open\"]\n",
    "df[\"high_over_low\"] = df[\"high\"] / df[\"low\"]\n",
    "df[\"daily_return\"] = df[\"close\"].pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8fa520",
   "metadata": {},
   "source": [
    "### 5.2 Technical Indicators\n",
    "\n",
    "Here we compute standard indicators used in quantiative analysis, such as moving averages, RSI, MACD, Bollinger Bands, momentum and stochastic oscillators.\n",
    "- **SMA (Simple Moving Average)**: Average of closing price over a window; helps identify trend direction.\n",
    "- **EMA (Exponential Moving Average)**: Similar to SMA but gives more weight to recent prices; reacts faster to change.\n",
    "- **RSI (Relative strength Index)**: Momentum indicator that measures recent gains vs. losses (0-100); detects overbough/oversold conditions.\n",
    "- **MACD (Moving Average Convergence Divergence)**: Shows the difference between fast & slow EMAs; useful for trend strengnth and reversals.\n",
    "- **Bollinger Bands**: Bands above/below SMA that expand/contract based on volatility; used to detect price extremes\n",
    "- **Momentum**: Measures volatility of price changes; helps capture accelerations.\n",
    "- **Stochastic Oscillator**: Compares closing price to recent highs/lows; signals potential reversals when crossing certain levels.\n",
    "- **OBV (On-Balance Volume)**: Cumulative Volume that adds on up days and subtracts on down days; used to confirm trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeda754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moving Averages\n",
    "df[\"SMA_10\"] = df[\"close\"].rolling(window=10).mean()\n",
    "df[\"SMA_20\"] = df[\"close\"].rolling(window=20).mean()\n",
    "df[\"EMA_20\"] = df[\"close\"].ewm(span=20).mean()\n",
    "df[\"EMA_50\"] = df[\"close\"].ewm(span=50).mean()\n",
    "\n",
    "# Volatility\n",
    "df[\"volatility_10\"] = df[\"daily_return\"].rolling(window=10).std()\n",
    "df[\"volatility_20\"] = df[\"daily_return\"].rolling(window=20).std()\n",
    "\n",
    "# RSI (14-day period)\n",
    "delta = df[\"close\"].diff()\n",
    "gain = np.where(delta > 0, delta, 0)\n",
    "loss = np.where(delta < 0, -delta, 0)\n",
    "avg_gain = pd.Series(gain, index=df.index).rolling(window=14).mean()\n",
    "avg_loss = pd.Series(loss, index=df.index).rolling(window=14).mean()\n",
    "rs = avg_gain / avg_loss\n",
    "df[\"RSI_14\"] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# MACD & Signal Line\n",
    "EMA_12 = df[\"close\"].ewm(span=12).mean()\n",
    "EMA_26 = df[\"close\"].ewm(span=26).mean()\n",
    "df[\"MACD\"] = EMA_12 - EMA_26\n",
    "df[\"MACD_signal\"] = df[\"MACD\"].ewm(span=9).mean\n",
    "\n",
    "# Bollinger Bands\n",
    "df[\"BB_upper\"] = df[\"SMA_20\"] + (2 * df[\"close\"].rolling(window=20).std())\n",
    "df[\"BB_lower\"] = df[\"SMA_20\"] - (2 * df[\"close\"].rolling(window=20).std())\n",
    "\n",
    "# Momentum \n",
    "df[\"momentum_5\"] = df[\"close\"] - df[\"close\"].shift(5)\n",
    "\n",
    "# Stochastic Oscillator \n",
    "low_14 = df[\"low\"].rolling(window=14).min()\n",
    "high_14 = df[\"high\"].rolling(window=14).max()\n",
    "df[\"stochastic_14\"] = (df[\"close\"] - low_14) / (high_14 - low_14) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191520c5",
   "metadata": {},
   "source": [
    "### 5.3 Volatility & Rolling Statistics\n",
    "\n",
    "We use rolling statistics to capture trends in market volatility and relative deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ccb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rolling_std_5\"] = df[\"close\"].rolling(window=5).std()\n",
    "df[\"rolling_std_10\"] = df[\"close\"].rolling(window=10).std()\n",
    "df[\"rolling_std_20\"] = df[\"close\"].rolling(window=20).std()\n",
    "\n",
    "df[\"rolling_mean_5\"] = df[\"close\"].rolling(window=5).mean()\n",
    "df[\"rolling_mean_10\"] = df[\"close\"].rolling(window=10).mean()\n",
    "df[\"rolling_mean_20\"] = df[\"close\"].rolling(window=20).mean()\n",
    "\n",
    "# Z-score\n",
    "df[\"zscore_close_10\"] = (df[\"close\"] - df[\"rolling_mean_10\"]) / df[\"rolling_std_10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb1d59c",
   "metadata": {},
   "source": [
    "### 5.3 Volume-Based Features\n",
    "\n",
    "Volume patterns can be strong predictors of price action. Here we include lagged volume, changes, and VWAP deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e689f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"volume_lag_1\"] = df[\"volume\"].shift(1)\n",
    "df[\"volume_change\"] = df[\"volume\"].pct_change()\n",
    "df[\"volume_over_rolling_avg_10\"] = df[\"volume\"] / df[\"volume\"].rolling(window=10).mean()\n",
    "df[\"vwap_diff\"] = df[\"close\"] - df[\"vwap\"]\n",
    "df[\"vwap_ratio\"] = df[\"close\"] / df[\"vwap\"]\n",
    "df[\"trade_count_change\"] = df[\"trade_count\"].pct_change()\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "obv = [0] # Initialize OBV list\n",
    "for i in range(1, len(df)):\n",
    "    if df['close'][i] > df['close'][i-1]:\n",
    "        obv.append(obv[-1] + df['volume'][i])\n",
    "    elif df['close'][i] < df['close'][i-1]:\n",
    "        obv.append(obv[-1] - df['volume'][i])\n",
    "    else:\n",
    "        obv.append(obv[-1])\n",
    "df['OBV'] = obv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3d3955",
   "metadata": {},
   "source": [
    "### 5.5 Statistical Features\n",
    "\n",
    "These features attempt to extract hidden structures, periodicity, and randomness from the time series - often useful in regime detection, anomaly spotting, and advanced modeling.\n",
    "\n",
    "- **shannon Entropy**: Measures the degree of randomness in a distribution. High entropy suggests noise or unpredictability, while low entropy implies more structure.\n",
    "- **Hurst Exponent**: Estimates the long-term memory of a series. A value > 0.5 implies trending behaviour, < 0.5 suggests mean-reverting tendencies, and ~0.5 indicates a random walk.\n",
    "- **FFT (Fast Fourier Transform)**: Decompose the time series into a sum of sine/cosine waves. Useful for identifying dominant periodicities (cycles).\n",
    "- **Autocorrelation (Lag 1)**: Measures the correlation between a value and its lagged version. High autocorrelation can indicate persistence or seasonality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86679bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shanon Entropy of Close Price Over a Rolling Window\n",
    "def shannon_entropy(series, bins=20):\n",
    "    \"\"\"Compute the Shannon entropy of a windowed series.\"\"\"\n",
    "    hist, _ = np.histogram(series.dropna(), bins=bins, density=True)\n",
    "    return entropy(hist)\n",
    "\n",
    "df[\"shannon_entropy_close\"] = df[\"close\"].rolling(window=20).apply(shannon_entropy, raw=False)\n",
    "\n",
    "# Hurst Exponent Over a Rolling Window\n",
    "def hurst_exponent(ts):\n",
    "    \"\"\"Estimate the Hurst exponent of a time series window.\"\"\"\n",
    "    lags = range(2, 20)\n",
    "    tau = [np.std(ts[lag:], ts[:-lag]) for lag in lags]\n",
    "    return np.polyfit(np.log(lags, np.log(tau)), 1)[0]\n",
    "\n",
    "df[\"hurst_exponent_close\"] = df[\"close\"].rolling(window=100).apply(hurst_exponent, raw=False)\n",
    "\n",
    "# FFT Top Components (Broadcast Statistic Global top 5 Magnitudes)\n",
    "fft_vals = np.fft.fft(df[\"close\"].dropna().values)\n",
    "fft_abs = np.abs(fft_vals)\n",
    "top_n = 5\n",
    "for i in range(1, top_n + 1):\n",
    "    df[f\"fft_{i}\"] = 0\n",
    "    df.loc[df.index[:len(fft_abs)], f\"fft_{i}\"] = fft_abs[i]  # broadcast value\n",
    "\n",
    "# Rolling Autocorrelation (Lag 1 to 3)\n",
    "df[\"autocorr_lag_1\"] = df[\"close\"].rolling(window=20).apply(lambda x: acf(x, nlags=1)[1], raw=False)\n",
    "df[\"autocorr_lag_2\"] = df[\"close\"].rolling(window=20).apply(lambda x: acf(x, nlags=2)[2], raw=False)\n",
    "df[\"autocorr_lag_3\"] = df[\"close\"].rolling(window=20).apply(lambda x: acf(x, nlags=3)[3], raw=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
